{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import conll2000\n",
    "from nltk import RegexpParser\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "pd.options.display.max_seq_items = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. The IOB format categorizes tagged tokens as I, O and B. Why are three tags necessary? What problem would be caused if we used I and O tags exclusively?\n",
    "\n",
    "The tags are I(inside), O(outside), B(Begin). B tag represents the beginning of the chunk while I tags occur after B as they represent the inside of the chunk. And O tags represent words that don't belong in any chunk.\n",
    "\n",
    "They are necessary to find named entities with multiple words. The three tags make it easier to construct the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Write a tag pattern to match noun phrases containing plural head nouns, e.g. \"many/JJ researchers/NNS\", \"two/CD weeks/NNS\", \"both/DT new/JJ positions/NNS\". Try to do this by generalizing the tag pattern that handled singular noun phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NN many/JJ researchers/NNS))\n"
     ]
    }
   ],
   "source": [
    "grammar = \"NN: {<DT>?(<JJ>*|<CD>*)<NN.>+}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "print(cp.parse(nltk.pos_tag(nltk.word_tokenize('many researchers'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NN both/DT new/JJ positions/NNS))\n"
     ]
    }
   ],
   "source": [
    "print(cp.parse(nltk.pos_tag(nltk.word_tokenize('both new positions'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Pick one of the three chunk types in the CoNLL corpus. Inspect the CoNLL corpus and try to observe any patterns in the POS tag sequences that make up this kind of chunk. Develop a simple chunker using the regular expression chunker nltk.RegexpParser. Discuss any tag sequences that are difficult to chunk reliably. \n",
    "\n",
    "VP Tag sequences are difficult ot chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Confidence/NN)\n",
      "  (PP in/IN)\n",
      "  (NP the/DT pound/NN)\n",
      "  (VP is/VBZ widely/RB expected/VBN to/TO take/VB)\n",
      "  (NP another/DT sharp/JJ dive/NN)\n",
      "  if/IN\n",
      "  (NP trade/NN figures/NNS)\n",
      "  (PP for/IN)\n",
      "  (NP September/NNP)\n",
      "  ,/,\n",
      "  due/JJ\n",
      "  (PP for/IN)\n",
      "  (NP release/NN)\n",
      "  (NP tomorrow/NN)\n",
      "  ,/,\n",
      "  (VP fail/VB to/TO show/VB)\n",
      "  (NP a/DT substantial/JJ improvement/NN)\n",
      "  (PP from/IN)\n",
      "  (NP July/NNP and/CC August/NNP)\n",
      "  (NP 's/POS near-record/JJ deficits/NNS)\n",
      "  ./.)\n",
      "(S\n",
      "  Chancellor/NNP\n",
      "  (PP of/IN)\n",
      "  (NP the/DT Exchequer/NNP)\n",
      "  (NP Nigel/NNP Lawson/NNP)\n",
      "  (NP 's/POS restated/VBN commitment/NN)\n",
      "  (PP to/TO)\n",
      "  (NP a/DT firm/NN monetary/JJ policy/NN)\n",
      "  (VP has/VBZ helped/VBN to/TO prevent/VB)\n",
      "  (NP a/DT freefall/NN)\n",
      "  (PP in/IN)\n",
      "  (NP sterling/NN)\n",
      "  (PP over/IN)\n",
      "  (NP the/DT past/JJ week/NN)\n",
      "  ./.)\n",
      "(S\n",
      "  But/CC\n",
      "  (NP analysts/NNS)\n",
      "  (VP reckon/VBP)\n",
      "  (NP underlying/VBG support/NN)\n",
      "  (PP for/IN)\n",
      "  (NP sterling/NN)\n",
      "  (VP has/VBZ been/VBN eroded/VBN)\n",
      "  (PP by/IN)\n",
      "  (NP the/DT chancellor/NN)\n",
      "  (NP 's/POS failure/NN)\n",
      "  (VP to/TO announce/VB)\n",
      "  (NP any/DT new/JJ policy/NN measures/NNS)\n",
      "  (PP in/IN)\n",
      "  (NP his/PRP$ Mansion/NNP House/NNP speech/NN)\n",
      "  (NP last/JJ Thursday/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "chunked = conll2000.chunked_sents()\n",
    "for sent in chunked[:3]:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Confidence', 'in', 'the', 'pound', 'is', 'widely', 'expected', 'to', 'take', 'another', 'sharp', 'dive', 'if', 'trade', 'figures', 'for', 'September', ',', 'due', 'for', 'release', 'tomorrow', ',', 'fail', 'to', 'show', 'a', 'substantial', 'improvement', 'from', 'July', 'and', 'August', \"'s\", 'near-record', 'deficits', '.']\n"
     ]
    }
   ],
   "source": [
    "con_sents = conll2000.sents()\n",
    "print(con_sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  79.9%%\n",
      "    Precision:     70.4%%\n",
      "    Recall:        60.6%%\n",
      "    F-Measure:     65.1%%\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "NP: {<DT>?<NN>*<JJ>*<NN.?>+}\n",
    "\"\"\"\n",
    "\n",
    "cp = RegexpParser(grammar)\n",
    "test_sents = conll2000.chunked_sents('test.txt', chunk_types = ['NP'])\n",
    "print(cp.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Mr./NNP Dillow/NNP)\n",
      "  (VP said/VBD)\n",
      "  (NP the/DT data/NNS)\n",
      "  (VP show/VBP)\n",
      "  (NP the/DT economy/NN)\n",
      "  ``/``\n",
      "  (VP is/VBZ)\n",
      "  still/RB\n",
      "  quite/RB\n",
      "  strong/JJ\n",
      "  ,/,\n",
      "  ''/''\n",
      "  but/CC\n",
      "  (NP suggestions/NNS)\n",
      "  that/IN\n",
      "  (NP much/NN)\n",
      "  (PP of/IN)\n",
      "  (NP the/DT spending/NN)\n",
      "  (VP went/VBD)\n",
      "  (PP on/IN)\n",
      "  (NP services/NNS)\n",
      "  (PP rather/RB than/IN)\n",
      "  (NP consumer/NN goods/NNS)\n",
      "  (VP should/MD reduce/VB)\n",
      "  (NP fears/NNS)\n",
      "  (PP of/IN)\n",
      "  (NP more/JJR import/NN rises/NNS)\n",
      "  ./.)\n",
      "(S\n",
      "  Certainly/RB\n",
      "  ,/,\n",
      "  (NP the/DT chancellor/NN)\n",
      "  (VP has/VBZ made/VBN)\n",
      "  (NP it/PRP)\n",
      "  clear/JJ\n",
      "  that/IN\n",
      "  (NP he/PRP)\n",
      "  (VP is/VBZ prepared/VBN to/TO increase/VB)\n",
      "  (NP interest/NN rates/NNS)\n",
      "  again/RB\n",
      "  if/IN\n",
      "  necessary/JJ\n",
      "  (VP to/TO both/DT ensure/VB)\n",
      "  that/IN\n",
      "  (NP a/DT substantial/JJ slowdown/NN)\n",
      "  (VP does/VBZ take/VB)\n",
      "  (NP place/NN)\n",
      "  and/CC\n",
      "  that/DT\n",
      "  (NP sterling/NN)\n",
      "  (VP does/VBZ n't/RB decline/VB)\n",
      "  further/JJ\n",
      "  ./.)\n",
      "(S\n",
      "  (NP Thursday/NNP)\n",
      "  ,/,\n",
      "  (NP he/PRP)\n",
      "  (VP reminded/VBD)\n",
      "  (NP his/PRP$ audience/NN)\n",
      "  that/IN\n",
      "  (NP the/DT government/NN)\n",
      "  ``/``\n",
      "  (VP can/MD not/RB allow/VB)\n",
      "  (NP the/DT necessary/JJ rigor/NN)\n",
      "  (PP of/IN)\n",
      "  (NP monetary/JJ policy/NN)\n",
      "  (VP to/TO be/VB undermined/VBN)\n",
      "  (PP by/IN)\n",
      "  (NP exchange/NN rate/NN weakness/NN)\n",
      "  ./.\n",
      "  ''/'')\n"
     ]
    }
   ],
   "source": [
    "for sent in chunked[21:24]:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  80.5%%\n",
      "    Precision:     71.4%%\n",
      "    Recall:        61.3%%\n",
      "    F-Measure:     66.0%%\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "NP: {<DT>?<NN>*<JJ.?>*<NN.?>+}\n",
    "\"\"\"\n",
    "\n",
    "cp = RegexpParser(grammar)\n",
    "print(cp.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. An early definition of chunk was the material that occurs between chinks. Develop a chunker that starts by putting the whole sentence in a single chunk, and then does the rest of its work solely by chinking. Determine which tags (or tag sequences) are most likely to make up chinks with the help of your own utility program. Compare the performance and simplicity of this approach relative to a chunker based entirely on chunk rules.\n",
    "\n",
    "Chink is done using }{"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  50.0%%\n",
      "    Precision:     12.6%%\n",
      "    Recall:         7.4%%\n",
      "    F-Measure:      9.4%%\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "NP: {<.*>+}  #Chunk Everything\n",
    "    }<PP.?|VB.?>+{\"\"\"\n",
    "\n",
    "cp = RegexpParser(grammar)\n",
    "print(cp.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  69.5%%\n",
      "    Precision:     32.8%%\n",
      "    Recall:        28.5%%\n",
      "    F-Measure:     30.5%%\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "NP: {<.*>+}  #Chunk Everything\n",
    "    }<IN|(VB.?)*(TO)?(DT)?(VB.?)>+{\"\"\"\n",
    "\n",
    "cp = RegexpParser(grammar)\n",
    "print(cp.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  69.5%%\n",
      "    Precision:     32.8%%\n",
      "    Recall:        28.5%%\n",
      "    F-Measure:     30.5%%\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "NP: {<.*>+}  #Chunk Everything\n",
    "    }<IN|VB.?>+{\"\"\"\n",
    "\n",
    "cp = RegexpParser(grammar)\n",
    "print(cp.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  69.5%%\n",
      "    Precision:     32.8%%\n",
      "    Recall:        28.5%%\n",
      "    F-Measure:     30.5%%\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "NP: {<.*>+}  #Chunk Everything\n",
    "    }<IN|VB.?>+{\"\"\"\n",
    "\n",
    "cp = RegexpParser(grammar)\n",
    "print(cp.evaluate(test_sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Write a tag pattern to cover noun phrases that contain gerunds, e.g. \"the/DT receiving/VBG end/NN\", \"assistant/NN managing/VBG editor/NN\". Add these patterns to the grammar, one per line. Test your work using some tagged sentences of your own devising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Manager', 'NNP'), ('found', 'VBD'), ('files', 'NNS')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize('Manager found files'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (CHUNK Manager/NNP found/VBD files/NNS))\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "GERUND: {<NN.?><VB.?><NN.?>} \n",
    "       {<DT>?<VB.?><NN.?>}\n",
    "        \"\"\"\n",
    "\n",
    "cp = RegexpParser(grammar)\n",
    "print(cp.parse(nltk.pos_tag(nltk.word_tokenize('Manager found files'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (CHUNK assistant/NN managing/VBG editor/NN))\n"
     ]
    }
   ],
   "source": [
    "print(cp.parse(nltk.pos_tag(nltk.word_tokenize('assistant managing editor'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (CHUNK the/DT receiving/VBG end/NN))\n"
     ]
    }
   ],
   "source": [
    "print(cp.parse(nltk.pos_tag(nltk.word_tokenize('the receiving end'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S Express/NNP yourself/PRP in/IN a/DT better/JJR)\n"
     ]
    }
   ],
   "source": [
    "print(cp.parse(nltk.pos_tag(nltk.word_tokenize('Express yourself in a better'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (CHUNK dancing/VBG club/NN))\n"
     ]
    }
   ],
   "source": [
    "print(cp.parse(nltk.pos_tag(nltk.word_tokenize('dancing club'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Write one or more tag patterns to handle coordinated noun phrases, e.g. \"July/NNP and/CC August/NNP\", \"all/DT your/PRP$ managers/NNS and/CC supervisors/NNS\", \"company/NN courts/NNS and/CC adjudicators/NNS\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (PAIR July/NNP and/CC August/NNP))\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"\"\"\n",
    "PAIR : {<DT>?<PRP$>?<NN.?>*<CC><NN.?>}\n",
    "        \"\"\"\n",
    "\n",
    "cp = RegexpParser(pattern)\n",
    "print(cp.parse(nltk.pos_tag(nltk.word_tokenize('July and August'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S all/DT your/PRP$ (PAIR managers/NNS and/CC supervisors/NNS))\n"
     ]
    }
   ],
   "source": [
    "print(cp.parse(nltk.pos_tag(nltk.word_tokenize('all your managers and supervisors'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (PAIR company/NN courts/NNS and/CC adjudicators/NNS))\n"
     ]
    }
   ],
   "source": [
    "print(cp.parse(nltk.pos_tag(nltk.word_tokenize('company courts and adjudicators'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S You/PRP and/CC I/PRP)\n"
     ]
    }
   ],
   "source": [
    "print(cp.parse(nltk.pos_tag(nltk.word_tokenize(''))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. Carry out the following evaluation tasks for any of the chunkers you have developed earlier. (Note that most chunking corpora contain some internal inconsistencies, such that any reasonable rule-based approach will produce errors.)\n",
    "1. Evaluate your chunker on 100 sentences from a chunked corpus, and report the precision, recall and F-measure.\n",
    "2. Use the chunkscore.missed() and chunkscore.incorrect() methods to identify the errors made by your chunker. Discuss.\n",
    "3. Compare the performance of your chunker to the baseline chunker discussed in the evaluation section of this chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  82.3%%\n",
      "    Precision:     73.6%%\n",
      "    Recall:        67.8%%\n",
      "    F-Measure:     70.6%%\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "NP: {<DT>?<NN.?>*<JJ.?>*<NN.?>+}\n",
    "{<PRP><NN.?>*}\n",
    "\"\"\"\n",
    "\n",
    "cp = RegexpParser(grammar)\n",
    "result = cp.evaluate(test_sents)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ImmutableTree('NP', [('Coca-Cola', 'NNP'), ('Enterprises', 'NNPS')]),\n",
       " ImmutableTree('NP', [('His', 'PRP$'), ('commanding', 'NN'), ('officer', 'NN')]),\n",
       " ImmutableTree('NP', [('as', 'RB'), ('much', 'JJ'), ('as', 'IN'), ('$', '$'), ('15,000', 'CD')]),\n",
       " ImmutableTree('NP', [('April', 'NNP'), ('1987', 'CD')]),\n",
       " ImmutableTree('NP', [('The', 'DT'), ('first', 'JJ'), ('two', 'CD'), ('games', 'NNS')]),\n",
       " ImmutableTree('NP', [('many', 'RB'), ('more', 'JJR')]),\n",
       " ImmutableTree('NP', [('The', 'DT'), ('only', 'RB'), ('safe', 'JJ'), ('sex', 'NN')]),\n",
       " ImmutableTree('NP', [(\"'s\", 'POS'), ('Baby', 'NNP'), ('Doc', 'NNP'), ('Duvalier', 'NNP')]),\n",
       " ImmutableTree('NP', [('her', 'PRP$'), ('husband', 'NN')]),\n",
       " ImmutableTree('NP', [('its', 'PRP$'), ('non-trade', 'JJ'), ('loans', 'NNS')]),\n",
       " ImmutableTree('NP', [('Democrats', 'NNP'), ('Bill', 'NNP'), ('Bradley', 'NNP'), ('and', 'CC'), ('John', 'NNP'), ('Glenn', 'NNP')]),\n",
       " ImmutableTree('NP', [('about', 'RB'), ('$', '$'), ('25', 'CD'), ('million', 'CD')]),\n",
       " ImmutableTree('NP', [('each', 'DT'), ('$', '$'), ('1,000', 'CD'), ('face', 'NN'), ('amount', 'NN')]),\n",
       " ImmutableTree('NP', [('Shearson', 'NNP')]),\n",
       " ImmutableTree('NP', [('most', 'RBS'), ('trading', 'NN')]),\n",
       " ImmutableTree('NP', [('Aug.', 'NNP'), ('6', 'CD'), (',', ','), ('1987', 'CD')]),\n",
       " ImmutableTree('NP', [('June', 'NNP'), ('1', 'CD'), (',', ','), ('1987', 'CD')]),\n",
       " ImmutableTree('NP', [('a', 'DT'), ('private', 'JJ'), ('meeting', 'NN')]),\n",
       " ImmutableTree('NP', [('Mission', 'NNP'), ('Resource', 'NNP'), ('Partners', 'NNPS')]),\n",
       " ImmutableTree('NP', [(\"'s\", 'POS'), ('government-relations', 'NNS'), ('staff', 'VBP')])]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result.missed())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ImmutableTree('NP', [(\"'s\", 'POS')]),\n",
       " ImmutableTree('NP', [('a', 'DT'), ('bit', 'NN')]),\n",
       " ImmutableTree('NP', [('company', 'NN')]),\n",
       " ImmutableTree('NP', [('a', 'DT')]),\n",
       " ImmutableTree('NP', [('bus', 'NN'), ('drivers', 'NNS')]),\n",
       " ImmutableTree('NP', [('Ohio-based', 'JJ'), ('company', 'NN')]),\n",
       " ImmutableTree('NP', [('approval', 'NN')]),\n",
       " ImmutableTree('NP', [('increase', 'NN')]),\n",
       " ImmutableTree('NP', [('limit', 'NN')]),\n",
       " ImmutableTree('NP', [('%', 'NN')]),\n",
       " ImmutableTree('NP', [('consecutive', 'JJ'), ('No.', 'NN')]),\n",
       " ImmutableTree('NP', [('a', 'DT')]),\n",
       " ImmutableTree('NP', [('years', 'NNS')]),\n",
       " ImmutableTree('NP', [('%', 'NN')]),\n",
       " ImmutableTree('NP', [('Elkhorn', 'NNP')]),\n",
       " ImmutableTree('NP', [('victories', 'NNS')]),\n",
       " ImmutableTree('NP', [('shares', 'NNS')]),\n",
       " ImmutableTree('NP', [('Pope', 'NNP')]),\n",
       " ImmutableTree('NP', [('first', 'JJ'), ('intelligence', 'NN'), ('service', 'NN')]),\n",
       " ImmutableTree('NP', [('%', 'NN')])]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result.incorrect())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  84.2%%\n",
      "    Precision:     68.7%%\n",
      "    Recall:        68.8%%\n",
      "    F-Measure:     68.7%%\n"
     ]
    }
   ],
   "source": [
    "grammar = r\"\"\"\n",
    "NP: {<DT>?<NN.?>*<JJ.?>*<NN.?>+}\n",
    "{<PRP><NN.?>*}\n",
    "{<DT>}\n",
    "{<POS>}\n",
    "\"\"\"\n",
    "\n",
    "cp = RegexpParser(grammar)\n",
    "result = cp.evaluate(test_sents)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ImmutableTree('NP', [('Coca-Cola', 'NNP'), ('Enterprises', 'NNPS')]),\n",
       " ImmutableTree('NP', [('His', 'PRP$'), ('commanding', 'NN'), ('officer', 'NN')]),\n",
       " ImmutableTree('NP', [('as', 'RB'), ('much', 'JJ'), ('as', 'IN'), ('$', '$'), ('15,000', 'CD')]),\n",
       " ImmutableTree('NP', [('April', 'NNP'), ('1987', 'CD')]),\n",
       " ImmutableTree('NP', [('The', 'DT'), ('first', 'JJ'), ('two', 'CD'), ('games', 'NNS')]),\n",
       " ImmutableTree('NP', [('many', 'RB'), ('more', 'JJR')]),\n",
       " ImmutableTree('NP', [('The', 'DT'), ('only', 'RB'), ('safe', 'JJ'), ('sex', 'NN')]),\n",
       " ImmutableTree('NP', [(\"'s\", 'POS'), ('Baby', 'NNP'), ('Doc', 'NNP'), ('Duvalier', 'NNP')]),\n",
       " ImmutableTree('NP', [('her', 'PRP$'), ('husband', 'NN')]),\n",
       " ImmutableTree('NP', [('its', 'PRP$'), ('non-trade', 'JJ'), ('loans', 'NNS')])]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result.missed())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ImmutableTree('NP', [(\"'s\", 'POS')]),\n",
       " ImmutableTree('NP', [('a', 'DT'), ('bit', 'NN')]),\n",
       " ImmutableTree('NP', [('company', 'NN')]),\n",
       " ImmutableTree('NP', [('a', 'DT')]),\n",
       " ImmutableTree('NP', [('bus', 'NN'), ('drivers', 'NNS')]),\n",
       " ImmutableTree('NP', [('Ohio-based', 'JJ'), ('company', 'NN')]),\n",
       " ImmutableTree('NP', [('approval', 'NN')]),\n",
       " ImmutableTree('NP', [('increase', 'NN')]),\n",
       " ImmutableTree('NP', [('limit', 'NN')]),\n",
       " ImmutableTree('NP', [('%', 'NN')])]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result.incorrect())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
