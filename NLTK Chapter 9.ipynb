{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Feature Based Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grammarical Features\n",
    "\n",
    "In contrast to feature extractors, which record features that have been automatically detected, we are now going to declare the features of words and phrases. We start off with a very simple example, using dictionaries to store features and their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kim = {'CAT': 'NP', 'ORTH': 'Kim', 'REF':'k'}\n",
    "chase = {'CAT':'V', 'ORTH': 'chased', 'REL': 'chase'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAT - Grammatical Category<br>\n",
    "ORTH - Orthography (spelling)<br>\n",
    "The above are shared features<br>\n",
    "\n",
    "Semantically-oriented feature: kim['**REF**'] is intended to give the referent of kim, while chase['**REL**'] gives the relation expressed by chase. In the context of rule-based grammars, such pairings of features and values are known as feature **structures**.\n",
    "\n",
    "Feature structures include various kinds of information about grammatical entities. \n",
    "\n",
    "In the case of a verb, one must know what 'semantic role' is played by the arguments of the verb. For example, 'chased', the subject plays the role of 'agent' while object has the role of 'patient'. \n",
    "\n",
    " Let's add this information, using 'sbj' and 'obj' as placeholders which will get filled once the verb combines with its grammatical arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chase['AGT'] = 'sbj'\n",
    "chase['PAT'] = 'obj'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we process 'Kim chased Lee', we want to bind the verb's agent role to the subject and the patient role to the 'object'. We do this by linking to the REF feature of the relevant NP.\n",
    "\n",
    "In the following example, we make the simple-minded assumption that the NPs immediately to the left and right of the verb are the subject and object respectively. We also add a feature structure for Lee to complete the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORTH  ==> chased\n",
      "REL   ==> chase\n",
      "AGT   ==> k\n",
      "PAT   ==> l\n"
     ]
    }
   ],
   "source": [
    "sent = 'Kim chased Lee'\n",
    "tokens = sent.split()\n",
    "lee = {'CAT': 'NP', 'ORTH': 'Lee', 'REF': 'l'}\n",
    "\n",
    "def lex2fs(word):\n",
    "    for fs in [kim, lee, chase]:\n",
    "        if fs['ORTH'] == word:\n",
    "            return fs\n",
    "        \n",
    "subj, verb, obj = lex2fs(tokens[0]), lex2fs(tokens[1]), lex2fs(tokens[2])\n",
    "verb['AGT'] = subj['REF']\n",
    "verb['PAT'] = obj['REF']\n",
    "\n",
    "for k in ['ORTH', 'REL', 'AGT', 'PAT']:\n",
    "    print('%-5s ==> %s' % (k, verb[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same approach could be adopted for a different verb, say surprise, though in this case, the subject would play the role of \"source\" (SRC) and the object, the role of \"experiencer\" (EXP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "surprise = {'CAT': 'V', 'ORTH': 'surprised', 'REL': 'surprise',\n",
    "       'SRC': 'sbj', 'EXP': 'obj'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this type of construction of feature structures is ad hoc. We want something more generic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% start S\n",
      "# ###################\n",
      "# Grammar Productions\n",
      "# ###################\n",
      "# S expansion productions\n",
      "S -> NP[NUM=?n] VP[NUM=?n]\n",
      "# NP expansion productions\n",
      "NP[NUM=?n] -> N[NUM=?n] \n",
      "NP[NUM=?n] -> PropN[NUM=?n] \n",
      "NP[NUM=?n] -> Det[NUM=?n] N[NUM=?n]\n",
      "NP[NUM=pl] -> N[NUM=pl] \n",
      "# VP expansion productions\n",
      "VP[TENSE=?t, NUM=?n] -> IV[TENSE=?t, NUM=?n]\n",
      "VP[TENSE=?t, NUM=?n] -> TV[TENSE=?t, NUM=?n] NP\n",
      "# ###################\n",
      "# Lexical Productions\n",
      "# ###################\n",
      "Det[NUM=sg] -> 'this' | 'every'\n",
      "Det[NUM=pl] -> 'these' | 'all'\n",
      "Det -> 'the' | 'some' | 'several'\n",
      "PropN[NUM=sg]-> 'Kim' | 'Jody'\n",
      "N[NUM=sg] -> 'dog' | 'girl' | 'car' | 'child'\n",
      "N[NUM=pl] -> 'dogs' | 'girls' | 'cars' | 'children' \n",
      "IV[TENSE=pres,  NUM=sg] -> 'disappears' | 'walks'\n",
      "TV[TENSE=pres, NUM=sg] -> 'sees' | 'likes'\n",
      "IV[TENSE=pres,  NUM=pl] -> 'disappear' | 'walk'\n",
      "TV[TENSE=pres, NUM=pl] -> 'see' | 'like'\n",
      "IV[TENSE=past] -> 'disappeared' | 'walked'\n",
      "TV[TENSE=past] -> 'saw' | 'liked'\n"
     ]
    }
   ],
   "source": [
    "nltk.data.show_cfg('grammars/book_grammars/feat0.fcfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Feature Structures\n",
    "\n",
    "Feature Structures in NLTK are declared with the FeatStruct() constructor. Atomic feature values can be strings or integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ NUM   = 'sg'   ]\n",
      "[ TENSE = 'past' ]\n"
     ]
    }
   ],
   "source": [
    "fs1 = nltk.FeatStruct(TENSE = 'past', NUM = 'sg')\n",
    "print(fs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A feature structure is actually just a kind of dictionary, and so we access its values by indexing in the usual way. We can use our familiar syntax to assign values to features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fm'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs1 = nltk.FeatStruct(PER = 3, NUM = 'pl', GND= 'fm')\n",
    "fs1['GND']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ CASE = 'acc' ]\n",
      "[ GND  = 'fm'  ]\n",
      "[ NUM  = 'pl'  ]\n",
      "[ PER  = 3     ]\n"
     ]
    }
   ],
   "source": [
    "fs1['CASE'] = 'acc'\n",
    "print(fs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also define feature structures that have complex values, as discussed earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[       [ CASE = 'acc' ] ]\n",
      "[ AGR = [ GND  = 'fm'  ] ]\n",
      "[       [ NUM  = 'pl'  ] ]\n",
      "[       [ PER  = 3     ] ]\n",
      "[                        ]\n",
      "[ POS = 'N'              ]\n"
     ]
    }
   ],
   "source": [
    "fs2 = nltk.FeatStruct(POS = 'N', AGR = fs1)\n",
    "print(fs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CASE='acc', GND='fm', NUM='pl', PER=3]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs2['AGR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative method of specifying feature structures is to use a bracketed string consisting of feature-value pairs in the format feature=value, where values may themselves be feature structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AGR=[GND='fem', NUM='pl', PER=3], POS='N']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FeatStruct('[POS = \"N\", AGR = [PER =3, GND = \"fem\", NUM = \"pl\"]]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature structures are not inherently tied to linguistic objects; they are general purpose structures for representing knowledge. For example, we could encode information about a person in a feature structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AGE=33, NAME='Lee', TELNO='012823']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.FeatStruct(NAME = 'Lee', TELNO= '012823', AGE = 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Structures can be viewed as Directed Acyclic Graphs \n",
    "\n",
    "In order to indicate reentrancy in our matrix-style representations, we will prefix the first occurrence of a shared feature structure with an integer in parentheses, such as (1). Any later reference to that structure will use the notation ->(1), as shown below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ADDRESS = (1) [ NUMBER = 74           ] ]\n",
      "[               [ STREET = 'RUE PASCAL' ] ]\n",
      "[                                         ]\n",
      "[ NAME    = 'LEE'                         ]\n",
      "[                                         ]\n",
      "[ SPOUSE  = [ ADDRESS -> (1)  ]           ]\n",
      "[           [ NAME    = 'KIM' ]           ]\n"
     ]
    }
   ],
   "source": [
    "f1 = nltk.FeatStruct(\"\"\"[NAME = 'LEE', ADDRESS =(1)[NUMBER = 74, \n",
    "                    STREET = 'RUE PASCAL'], SPOUSE = [NAME = 'KIM', \n",
    "                    ADDRESS -> (1)]]\"\"\")\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NUMBER=74, STREET='RUE PASCAL']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1['SPOUSE']['ADDRESS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bracketed integer is sometimes called a tag or a coindex. The choice of integer is not significant. There can be any number of tags within a single feature structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ A = 'a'             ]\n",
      "[                     ]\n",
      "[ B = (1) [ C = 'c' ] ]\n",
      "[                     ]\n",
      "[ D -> (1)            ]\n",
      "[ E -> (1)            ]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.FeatStruct(\"[A = 'a', B=(1)[C= 'c'], D->(1), E->(1)]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Subsumption and Unification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is standard to think of feature structures as providing partial information about some object, in the sense that we can order feature structures according to how much information they contain.\n",
    "\n",
    "(23)\n",
    "a.  [NUMBER =74]\n",
    "\n",
    "b.  [NUMBER =74]\n",
    "    [STREET = 'RUE PASCAL]\n",
    "\n",
    "c. [NUMBER =74]\n",
    "    [STREET = 'RUE PASCAL]\n",
    "    [CITY = 'PARIS]\n",
    "    \n",
    "This ordering is called **subsumption**. FS0 subsumes FS1 if all information contained in FS0 is also contained in Fs1. We use the symbol ⊑ to represent subsumption.\n",
    "\n",
    "When we add the possibility of reentrancy, we need to be more careful about how we describe subsumption: if FS0 ⊑ FS1, then FS1 must have all the paths and reentrancies of FS0.\n",
    "\n",
    "So we have seen that some feature structures carry more information than others. How do we go about adding more information to a given feature structure? For example, we might decide that addresses should consist of not just a street number and a street name, but also a city. \n",
    "\n",
    "Merging information from two features is called **unification** and is supported by **unify()** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CITY='PARIS', NUMBER=74, STREET='RUE PASCAL']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs1 = nltk.FeatStruct(NUMBER = 74, STREET = 'RUE PASCAL')\n",
    "fs2 = nltk.FeatStruct(CITY = 'PARIS')\n",
    "fs1.unify(fs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NUMBER=74, STREET='RUE PASCAL']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unification is formally defined as a (partial) binary operation: FS0 ⊔ FS1. Unification is symmetric, so FS0 ⊔ FS1 = FS1 ⊔ FS0. The same is true in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CITY='PARIS', NUMBER=74, STREET='RUE PASCAL']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs2.unify(fs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we unify two feature structures which stand in the subsumption relationship, then the result of unification is the most informative of the two:\n",
    "\n",
    "If FS0 ⊑ FS1, then FS0 ⊔ FS1 = FS1\n",
    "\n",
    "Unification between FS0 and FS1 will fail if the two feature structures share a path π, but the value of π in FS0 is a distinct atom from the value of π in FS1. This is implemented by setting the result of unification to be None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "fs0 = nltk.FeatStruct(A = 'a')\n",
    "fs1 = nltk.FeatStruct(A = 'b')\n",
    "print(fs0.unify(fs1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ A = 'a' ]\n"
     ]
    }
   ],
   "source": [
    "fs2 = nltk.FeatStruct(A = 'a')\n",
    "print(fs0.unify(fs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we look at how unification interacts with structure-sharing, things become really interesting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ SPOUSE = [ ADDRESS = [ CITY = 'PARIS' ] ] ]\n"
     ]
    }
   ],
   "source": [
    "fs0 = nltk.FeatStruct(\"\"\"[NAME = 'LEE', ADDRESS = [NUMBER = 74, STREET = 'RUE PASCAL'],\n",
    "                     AGE = 33, SPOUSE = [NAME = 'KIM', ADDRESS = [NUMBER = 74, STREET = 'RUE PASCAL']]]\"\"\")\n",
    "print(fs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when we augment Kim's address with a specification for CITY? Notice that fs1 needs to include the whole path from the root of the feature structure down to CITY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ADDRESS = [ NUMBER = 74           ]               ]\n",
      "[           [ STREET = 'RUE PASCAL' ]               ]\n",
      "[                                                   ]\n",
      "[ AGE     = 33                                      ]\n",
      "[ NAME    = 'LEE'                                   ]\n",
      "[                                                   ]\n",
      "[           [           [ CITY   = 'PARIS'      ] ] ]\n",
      "[           [ ADDRESS = [ NUMBER = 74           ] ] ]\n",
      "[ SPOUSE  = [           [ STREET = 'RUE PASCAL' ] ] ]\n",
      "[           [                                     ] ]\n",
      "[           [ NAME    = 'KIM'                     ] ]\n"
     ]
    }
   ],
   "source": [
    "fs1 = nltk.FeatStruct('[SPOUSE = [ADDRESS = [CITY = \"PARIS\"]]]')\n",
    "print(fs1.unify(fs0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By contrast, the result is very different if fs1 is unified with the structure-sharing version fs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[               [ CITY   = 'PARIS'      ] ]\n",
      "[ ADDRESS = (1) [ NUMBER = 74           ] ]\n",
      "[               [ STREET = 'RUE PASCAL' ] ]\n",
      "[                                         ]\n",
      "[ NAME    = 'LEE'                         ]\n",
      "[                                         ]\n",
      "[ SPOUSE  = [ ADDRESS -> (1)  ]           ]\n",
      "[           [ NAME    = 'KIM' ]           ]\n"
     ]
    }
   ],
   "source": [
    "fs2 = nltk.FeatStruct(\"\"\"[NAME = LEE, ADDRESS = (1)[NUMBER = 74, STREET = 'RUE PASCAL'],\n",
    "                        SPOUSE = [NAME = KIM, ADDRESS -> (1)]]\"\"\")\n",
    "\n",
    "print(fs1.unify(fs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than just updating what was in effect Kim's \"copy\" of Lee's address, we have now updated both their addresses at the same time. More generally, if a unification adds information to the value of some path π, then that unification simultaneously updates the value of any path that is equivalent to π.\n",
    "\n",
    "Structure sharing can also be stated using variables such as ?x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ADDRESS1 = ?x ]\n",
      "[ ADDRESS2 = ?x ]\n"
     ]
    }
   ],
   "source": [
    "fs1 = nltk.FeatStruct(\"[ADDRESS1 = [NUMBER =74, STREE = 'RUE PASCAL']]\")\n",
    "fs2 = nltk.FeatStruct(\"[ADDRESS1 =?x, ADDRESS2 = ?x ]\")\n",
    "print(fs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ ADDRESS1 = (1) [ NUMBER = 74           ] ]\n",
      "[                [ STREE  = 'RUE PASCAL' ] ]\n",
      "[                                          ]\n",
      "[ ADDRESS2 -> (1)                          ]\n"
     ]
    }
   ],
   "source": [
    "print(fs1.unify(fs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extending a Feature Based Grammar\n",
    "\n",
    "##### Subcategorization\n",
    "\n",
    "In 8., we augmented our category labels to represent different kinds of verb, and used the labels IV and TV for intransitive and transitive verbs respectively. This allowed us to write productions like the following:\n",
    "\n",
    "(27)\t\t\n",
    "VP -> IV<br>\n",
    "VP -> TV NP\n",
    "\n",
    "Although we know that IV and TV are two kinds of V, they are just atomic nonterminal symbols from a CFG, as distinct from each other as any other pair of symbols. This notation doesn't let us say anything about verbs in general, e.g. we cannot say \"All lexical items of category V can be marked for tense\", since walk, say, is an item of category IV, not V. So, can we replace category labels such as  TV and IV by V along with a feature that tells us whether the verb combines with a following NP object or whether it can occur without any complement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "string = 'play a song on itunes'\n",
    "tokens= nltk.word_tokenize(string)\n",
    "tags= nltk.pos_tag(tokens)\n",
    "print(nltk.ne_chunk(tags).draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
